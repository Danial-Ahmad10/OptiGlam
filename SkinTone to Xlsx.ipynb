{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from openpyxl import Workbook\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl import load_workbook\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.impute import SimpleImputer\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Each image to 4,5,6 so that we can make resized faces to 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the main folder containing the subfolders\n",
    "main_folder_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Makeup Images new'\n",
    "\n",
    "# Loop through each subfolder in the main folder\n",
    "for subfolder_name in os.listdir(main_folder_path):\n",
    "    subfolder_path = os.path.join(main_folder_path, subfolder_name)\n",
    "    \n",
    "    # Check if the subfolder is actually a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Get a list of image files in the subfolder\n",
    "        image_files = [file for file in os.listdir(subfolder_path) if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
    "        \n",
    "        # Determine the number of images in the subfolder\n",
    "        num_images = len(image_files)\n",
    "        \n",
    "        # Rename each image file in the subfolder\n",
    "        for i, image_file in enumerate(image_files, start=4):\n",
    "            # If there are only 2 images, rename each image to 4, 5 respectively\n",
    "            if num_images == 2 and i > 5:\n",
    "                break\n",
    "            # Otherwise, rename each image to 4, 5, 6 respectively\n",
    "            new_name = str(i) + os.path.splitext(image_file)[1]\n",
    "            old_path = os.path.join(subfolder_path, image_file)\n",
    "            new_path = os.path.join(subfolder_path, new_name)\n",
    "            os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save face into folder and rename to 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021133FA4CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021133FA72E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "Unable to read E:\\University\\FYP Stuff\\Dataset\\Makeup Images new\\sabrinajetliâ€‹\\4.jpg. Skipping...\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Face Extraction Completed for 4.jpg!\n",
      "Face Extraction Completed for 4.jpg!\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "Face Extraction Completed for 4.jpg!\n"
     ]
    }
   ],
   "source": [
    "def detect_faces_in_folder(main_directory):\n",
    "    # Loop through each subfolder in the main directory\n",
    "    for subfolder_name in os.listdir(main_directory):\n",
    "        subfolder_path = os.path.join(main_directory, subfolder_name)\n",
    "        \n",
    "        # Check if the subfolder is actually a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # All files in the subfolder\n",
    "            files = os.listdir(subfolder_path)\n",
    "            \n",
    "            # Initialize counter for face image naming\n",
    "            face_counter = 1\n",
    "            \n",
    "            # Create MTCNN detector\n",
    "            detector = MTCNN()\n",
    "            \n",
    "            # Loop through each image file in the subfolder\n",
    "            for image_file in files:\n",
    "                image_path = os.path.join(subfolder_path, image_file)\n",
    "\n",
    "                # Reading the image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(f\"Unable to read {image_path}. Skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Detect faces in the image\n",
    "                faces = detector.detect_faces(image_rgb)\n",
    "\n",
    "                # Loop through each detected face\n",
    "                for idx, face in enumerate(faces):\n",
    "                    bounding_box = face['box']\n",
    "                    x, y, w, h = bounding_box\n",
    "\n",
    "                    min_face_size = 45\n",
    "                    if w > min_face_size and h > min_face_size:\n",
    "                        extracted_face = image[y:y + h, x:x + w]\n",
    "\n",
    "                        # Construct the path to store the extracted face image\n",
    "                        extracted_face_filename = f'{str(face_counter)}.jpg'\n",
    "                        extracted_face_path = os.path.join(subfolder_path, extracted_face_filename)\n",
    "\n",
    "                        # Write the extracted face image to the same subfolder\n",
    "                        cv2.imwrite(extracted_face_path, extracted_face)\n",
    "                        print(f\"Face Extraction Completed for {image_file}!\")\n",
    "                        \n",
    "                        # Increment face counter\n",
    "                        face_counter += 1\n",
    "                    else:\n",
    "                        print(f\"Face in {image_file} is too small and will be skipped.\")\n",
    "\n",
    "# Main folder containing subfolders\n",
    "main_directory = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Makeup Images new'\n",
    "detect_faces_in_folder(main_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out Missing Folders from Xlsx File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing folders: []\n"
     ]
    }
   ],
   "source": [
    "def find_missing_folders(main_folder, df):\n",
    "    # Get unique folder names from the DataFrame\n",
    "    df_folders = set(df['channelName'].tolist())\n",
    "\n",
    "    # List of missing folders\n",
    "    missing_folders = []\n",
    "\n",
    "    # Iterate through each subfolder in the main folder\n",
    "    for subfolder_name in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder_name)\n",
    "\n",
    "        # Check if the subfolder is a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Check if the subfolder name is not in the DataFrame\n",
    "            if subfolder_name not in df_folders:\n",
    "                missing_folders.append(subfolder_name)\n",
    "\n",
    "    return missing_folders\n",
    "\n",
    "# Example usage:\n",
    "main_folder = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Makeup Images'\n",
    "# Assuming 'df' is your DataFrame loaded from Excel\n",
    "# Load Excel file into DataFrame\n",
    "df = pd.read_excel('E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_dec.xlsx')\n",
    "\n",
    "# Find missing folders\n",
    "missing_folders = find_missing_folders(main_folder, df)\n",
    "print(\"Missing folders:\", missing_folders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply Model to FIRST face and store it into Xlsx File (NO LIGHTING CONDITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All needed Functions\n",
    "\n",
    "# Function to load the model\n",
    "def load_model():\n",
    "    model = tf.keras.models.load_model('E:\\\\University\\\\FYP Stuff\\\\Models For SkinTone Recognition\\\\Skintone_Recognition_lit.h5')\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Resize, normalize, and reshape the image\n",
    "    image = image.resize((224, 224))  \n",
    "    image = np.array(image) / 255.0  \n",
    "    image = np.expand_dims(image, axis=0)  \n",
    "    return image\n",
    "\n",
    "# Function to predict skintone using the model\n",
    "def predict_skintone(model, image):\n",
    "\n",
    "    #Predictions\n",
    "    prediction = model.predict(image)\n",
    "    return prediction\n",
    "\n",
    "# Function to process images in subfolders and update Excel file\n",
    "def process_images_and_update_excel(model, main_folder, excel_file):\n",
    "    # Load Excel file into DataFrame\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Iterate through each subfolder in the main folder\n",
    "    for subfolder_name in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder_name)\n",
    "        \n",
    "        # Check if the subfolder is actually a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Look for image files named \"1\" with different extensions\n",
    "            for ext in ['png', 'jpeg', 'jpg']:\n",
    "                image_path = os.path.join(subfolder_path, f\"1.{ext}\")\n",
    "                # Check if the image exists\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load and preprocess the image\n",
    "                    image = Image.open(image_path)\n",
    "                    image = preprocess_image(image)\n",
    "\n",
    "                    # Predict skintone using the model\n",
    "                    prediction = predict_skintone(model, image)\n",
    "\n",
    "                    skintone = np.argmax(prediction) + 1\n",
    "                    \n",
    "                    # Find the corresponding row in the DataFrame using the folder name\n",
    "                    row_index = df.index[df['channelName'] == subfolder_name].tolist()[0]\n",
    "                    \n",
    "                    # Store the skintone prediction in the \"Skintone\" column of the corresponding row\n",
    "                    df.loc[row_index, 'skinTone'] = skintone\n",
    "                    # Break the loop after finding the first image\n",
    "                    break\n",
    "\n",
    "    # Code to preserve Web link\n",
    "    # Create a new Workbook object and select active worksheet\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    # Convert DataFrame to rows and write to Excel worksheet\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True)):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            # Preserve hyperlink format for \"productLink\" column\n",
    "            if df.columns[c_idx - 1] == \"productLink\":\n",
    "                cell = ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "                cell.style = \"Hyperlink\"\n",
    "                cell.font = Font(underline=\"single\", color=\"0563C1\")\n",
    "            else:\n",
    "                ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "\n",
    "    # Location and name of new file to be saved\n",
    "    new_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'\n",
    "    wb.save(new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply Model to FIRST face and store it into Xlsx File (LIGHTING CONDITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All needed Functions\n",
    "\n",
    "# Function to load the model\n",
    "def load_model():\n",
    "    model = tf.keras.models.load_model('E:\\\\University\\\\FYP Stuff\\\\Models For SkinTone Recognition\\\\Skintone_Recognition_Multimodal1.h5')\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Resize, normalize, and reshape the image\n",
    "    image = image.resize((224, 224))  \n",
    "    image = np.array(image) / 255.0  \n",
    "    image = np.expand_dims(image, axis=0)  \n",
    "    return image\n",
    "\n",
    "# Function to predict skintone using the model\n",
    "def predict_skintone(model, image, lighting_text, classes):\n",
    "\n",
    "    # Convert lighting text to one-hot encoding\n",
    "    lighting_encoded = classes.index(lighting_text)\n",
    "    lighting_onehot = to_categorical(lighting_encoded, num_classes=3)\n",
    "\n",
    "    #Predictions\n",
    "    prediction = model.predict({'image_input': image, \n",
    "                                 'text_input': np.expand_dims(lighting_onehot, axis=0)})\n",
    "    return prediction\n",
    "\n",
    "# Function to process images in subfolders and update Excel file\n",
    "def process_images_and_update_excel(model, main_folder, excel_file):\n",
    "    # Load Excel file into DataFrame\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Iterate through each subfolder in the main folder\n",
    "    for subfolder_name in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder_name)\n",
    "        \n",
    "        # Check if the subfolder is actually a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Look for image files named \"1\" with different extensions\n",
    "            for ext in ['png', 'jpeg', 'jpg']:\n",
    "                image_path = os.path.join(subfolder_path, f\"1.{ext}\")\n",
    "                # Check if the image exists\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load and preprocess the image\n",
    "                    image = Image.open(image_path)\n",
    "                    image = preprocess_image(image)\n",
    "\n",
    "                    # Classes typed manually \n",
    "                    classes = ['poorly', 'video', 'well']\n",
    "                    \n",
    "                    # LIGHTING TEXT\n",
    "                    lighting_text = 'well'\n",
    "\n",
    "                    # Predict skintone using the model\n",
    "                    prediction = predict_skintone(model, image, lighting_text, classes)\n",
    "\n",
    "                    skintone = np.argmax(prediction) + 1\n",
    "                    \n",
    "                    # Find the corresponding row in the DataFrame using the folder name\n",
    "                    row_index = df.index[df['channelName'] == subfolder_name].tolist()[0]\n",
    "                    \n",
    "                    # Store the skintone prediction in the \"Skintone\" column of the corresponding row\n",
    "                    df.loc[row_index, 'skinTone'] = skintone\n",
    "                    # Break the loop after finding the first image\n",
    "                    break\n",
    "\n",
    "    # Code to preserve Web link\n",
    "    # Create a new Workbook object and select active worksheet\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    # Convert DataFrame to rows and write to Excel worksheet\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True)):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            # Preserve hyperlink format for \"productLink\" column\n",
    "            if df.columns[c_idx - 1] == \"productLink\":\n",
    "                cell = ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "                cell.style = \"Hyperlink\"\n",
    "                cell.font = Font(underline=\"single\", color=\"0563C1\")\n",
    "            else:\n",
    "                ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "\n",
    "    # Location and name of new file to be saved\n",
    "    new_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'\n",
    "    wb.save(new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing using functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Path to the main folder containing subfolders\n",
    "main_folder = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Makeup Images'\n",
    "# Path to the Excel file\n",
    "excel_file = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_dec.xlsx'\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Process images in subfolders and update Excel file\n",
    "process_images_and_update_excel(model, main_folder, excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for SECOND FACE (LIGHTING CONDITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Function to process images in subfolders and update Excel file\n",
    "def process_images_and_update_excel(model, main_folder, excel_file):\n",
    "    # Load Excel file into DataFrame\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Iterate through each subfolder in the main folder\n",
    "    for subfolder_name in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder_name)\n",
    "        \n",
    "        # Check if the subfolder is actually a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Look for image files named \"1\" with different extensions\n",
    "            for ext in ['png', 'jpeg', 'jpg']:\n",
    "                image_path = os.path.join(subfolder_path, f\"2.{ext}\")\n",
    "                # Check if the image exists\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load and preprocess the image\n",
    "                    image = Image.open(image_path)\n",
    "                    image = preprocess_image(image)\n",
    "\n",
    "                    # Classes typed manually \n",
    "                    classes = ['poorly', 'video', 'well']\n",
    "                    \n",
    "                    # LIGHTING TEXT\n",
    "                    lighting_text = 'well'\n",
    "\n",
    "                    # Predict skintone using the model\n",
    "                    prediction = predict_skintone(model, image, lighting_text, classes)\n",
    "\n",
    "                    skintone2 = np.argmax(prediction) + 1\n",
    "                    \n",
    "                    # Find the corresponding row in the DataFrame using the folder name\n",
    "                    row_index = df.index[df['channelName'] == subfolder_name].tolist()[0]\n",
    "                    \n",
    "                    # Store the skintone prediction in the \"Skintone\" column of the corresponding row\n",
    "                    df.loc[row_index, 'skinTone2'] = skintone2\n",
    "                    # Break the loop after finding the first image\n",
    "                    break\n",
    "\n",
    "    # Code to preserve Web link\n",
    "    # Create a new Workbook object and select active worksheet\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    # Convert DataFrame to rows and write to Excel worksheet\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True)):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            # Preserve hyperlink format for \"productLink\" column\n",
    "            if df.columns[c_idx - 1] == \"productLink\":\n",
    "                cell = ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "                cell.style = \"Hyperlink\"\n",
    "                cell.font = Font(underline=\"single\", color=\"0563C1\")\n",
    "            else:\n",
    "                ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "\n",
    "    # Location and name of new file to be saved\n",
    "    new_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'\n",
    "    wb.save(new_file_path)\n",
    "\n",
    "# Path to the main folder containing subfolders\n",
    "main_folder = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Makeup Images'\n",
    "# Path to the Excel file\n",
    "excel_file = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Process images in subfolders and update Excel file\n",
    "process_images_and_update_excel(model, main_folder, excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for SECOND FACE (NO LIGHTING CONDITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_skintone() missing 2 required positional arguments: 'lighting_text' and 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Process images in subfolders and update Excel file\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[43mprocess_images_and_update_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexcel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mprocess_images_and_update_excel\u001b[1;34m(model, main_folder, excel_file)\u001b[0m\n\u001b[0;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m preprocess_image(image)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict skintone using the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_skintone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m skintone2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find the corresponding row in the DataFrame using the folder name\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict_skintone() missing 2 required positional arguments: 'lighting_text' and 'classes'"
     ]
    }
   ],
   "source": [
    "# Function to process images in subfolders and update Excel file\n",
    "def process_images_and_update_excel(model, main_folder, excel_file):\n",
    "    # Load Excel file into DataFrame\n",
    "    df = pd.read_excel(excel_file)\n",
    "\n",
    "    # Iterate through each subfolder in the main folder\n",
    "    for subfolder_name in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder_name)\n",
    "        \n",
    "        # Check if the subfolder is actually a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Look for image files named \"1\" with different extensions\n",
    "            for ext in ['png', 'jpeg', 'jpg']:\n",
    "                image_path = os.path.join(subfolder_path, f\"2.{ext}\")\n",
    "                # Check if the image exists\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load and preprocess the image\n",
    "                    image = Image.open(image_path)\n",
    "                    image = preprocess_image(image)\n",
    "\n",
    "                    # Predict skintone using the model\n",
    "                    prediction = predict_skintone(model, image)\n",
    "\n",
    "                    skintone2 = np.argmax(prediction) + 1\n",
    "                    \n",
    "                    # Find the corresponding row in the DataFrame using the folder name\n",
    "                    row_index = df.index[df['channelName'] == subfolder_name].tolist()[0]\n",
    "                    \n",
    "                    # Store the skintone prediction in the \"Skintone\" column of the corresponding row\n",
    "                    df.loc[row_index, 'skinTone2'] = skintone2\n",
    "                    # Break the loop after finding the first image\n",
    "                    break\n",
    "\n",
    "    # Code to preserve Web link\n",
    "    # Create a new Workbook object and select active worksheet\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "\n",
    "    # Convert DataFrame to rows and write to Excel worksheet\n",
    "    for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True)):\n",
    "        for c_idx, value in enumerate(row, 1):\n",
    "            # Preserve hyperlink format for \"productLink\" column\n",
    "            if df.columns[c_idx - 1] == \"productLink\":\n",
    "                cell = ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "                cell.style = \"Hyperlink\"\n",
    "                cell.font = Font(underline=\"single\", color=\"0563C1\")\n",
    "            else:\n",
    "                ws.cell(row=r_idx + 1, column=c_idx, value=value)\n",
    "\n",
    "    # Location and name of new file to be saved\n",
    "    new_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'\n",
    "    wb.save(new_file_path)\n",
    "\n",
    "# Path to the main folder containing subfolders\n",
    "main_folder = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Makeup Images'\n",
    "# Path to the Excel file\n",
    "excel_file = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Process images in subfolders and update Excel file\n",
    "process_images_and_update_excel(model, main_folder, excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Average of 2 Skintones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danial1\\AppData\\Local\\Temp\\ipykernel_6472\\987838994.py:16: FutureWarning: Setting the `book` attribute is not part of the public API, usage can give unexpected or corrupted results and will be removed in a future version\n",
      "  writer.book = wb\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_and_add_column(input_file_path, output_file_path):\n",
    "    # Load the existing Excel file\n",
    "    wb = load_workbook(input_file_path)\n",
    "    \n",
    "    # Iterate through each sheet\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        # Read the sheet into DataFrame\n",
    "        df = pd.read_excel(input_file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # Calculate the average of the two columns and store it in a new column named \"SkinTone\"\n",
    "        if 'skinTone' in df.columns and 'skinTone2' in df.columns:\n",
    "            df['SkinTone'] = df[['skinTone', 'skinTone2']].astype(float).mean(axis=1)\n",
    "        \n",
    "        # Write the updated DataFrame back to the sheet\n",
    "        with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "            writer.book = wb\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Example usage:\n",
    "input_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_MST.xlsx'  \n",
    "output_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_Final.xlsx' \n",
    "calculate_average_and_add_column(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Missing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danial1\\AppData\\Local\\Temp\\ipykernel_7080\\864626655.py:18: FutureWarning: Setting the `book` attribute is not part of the public API, usage can give unexpected or corrupted results and will be removed in a future version\n",
      "  writer.book = wb\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_and_add_column(input_file_path, output_file_path):\n",
    "    # Load the existing Excel file\n",
    "    wb = load_workbook(input_file_path)\n",
    "    \n",
    "    # Iterate through each sheet\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        # Read the sheet into DataFrame\n",
    "        df = pd.read_excel(input_file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # Initialize the SimpleImputer with mean strategy\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "        # Handle missing values for the 'SkinTone' column\n",
    "        df['SkinTone'] = imputer.fit_transform(df[['SkinTone']])\n",
    "        \n",
    "        # Write the updated DataFrame back to the sheet\n",
    "        with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "            writer.book = wb\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Example usage:\n",
    "input_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_Final.xlsx'  \n",
    "output_file_path = 'E:\\\\University\\\\FYP Stuff\\\\Dataset\\\\Youtube_Dataset_Final.xlsx' \n",
    "calculate_average_and_add_column(input_file_path, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyFirstEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
